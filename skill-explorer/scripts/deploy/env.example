# ============================================================================
# Skill Explorer Production Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your values:
#   cp env.example .env
#
# Then run:
#   ./deploy-prod.sh
# ============================================================================

# ============================================================================
# Cloudflare Tunnel Configuration
# ============================================================================
# Tunnel name - creates a separate tunnel for skill-explorer
CLOUDFLARE_TUNNEL_NAME="skill-explorer"

# Domain for skill-explorer
SKILLS_HOSTNAME="skills.axiologic.dev"

# ============================================================================
# Router Configuration
# ============================================================================
# Port for the ploinky router (default: 8888)
ROUTER_PORT=8888

# Public URL (auto-generated from SKILLS_HOSTNAME if not set)
# PLOINKY_ROUTER_URL=https://skills.axiologic.dev

# ============================================================================
# LLM API Keys (at least one required)
# ============================================================================
# OpenAI API Key (for GPT models)
# OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic API Key (for Claude models) - RECOMMENDED
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google Gemini API Key
# GEMINI_API_KEY=your-gemini-key-here

# Mistral API Key
# MISTRAL_API_KEY=your-mistral-key-here

# DeepSeek API Key
# DEEPSEEK_API_KEY=your-deepseek-key-here

# OpenRouter API Key (for multiple model access)
# OPENROUTER_API_KEY=your-openrouter-key-here

# ============================================================================
# Debug Options
# ============================================================================
# Enable debug logging for LLM calls
# LLMAgentClient_DEBUG=true

# Add delay to verbose output (milliseconds)
# LLMAgentClient_VERBOSE_DELAY=100
